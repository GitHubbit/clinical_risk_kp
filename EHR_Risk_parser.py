#!/usr/bin/env python3

import pandas as pd
import json
import sys, os

def parse_ehr_risk(data_folder):
    nodes_filename = "ehr_risk_nodes_data_2022_06_01.csv"
    edges_filename = "ehr_risk_edges_data_2022_06_01.csv"
    nodes_filepath = os.path.join(data_folder, nodes_filename)
    edges_filepath = os.path.join(data_folder, edges_filename)
    nodes_data = pd.read_csv(nodes_filepath, sep = ',')
    edges_data = pd.read_csv(edges_filepath, sep = ',')
    
    edges_data["num_patients_with_condition"] = 10**(edges_data['log_positive_patient_count']) # convert log pos patient count to an actual # 
    edges_data["num_patients_without_condition"] = 10**(edges_data['log_negative_patient_count']) # convert log neg patient count to an actual # 
#     edges_data["num_patients_with_condition"] = np.random.poisson(edges_data['num_patients_with_condition'])  # add poisson noise injection
#     edges_data["num_patients_without_condition"] = np.random.poisson(edges_data['num_patients_without_condition']) # add poisson noise injection
#     edges_data = edges_data.drop(['log_positive_patient_count', 'log_negative_patient_count'], axis=1)
    
    # merge the edges and nodes dataframes (dropping "xref" bc it's empty)
    ## merging subject info from nodes df
    kg = pd.merge(edges_data, nodes_data[['id', 'name', 'category']], left_on='subject', right_on = 'id')
    kg.rename(columns = {'category_x':'predicate_category',
                         'category_y': 'subject_category',
                         'id': 'subject_id',
                         'name': 'subject_name'},
              inplace = True)
    ## merging object info from nodes df
    kg = pd.merge(kg, nodes_data[['id', 'name', 'category']], left_on='object', right_on = 'id')
        
    kg.rename(columns = {'id':'object_id',
                         'category': 'object_category',
                         'name': 'object_name'}, inplace = True)
    
#     kg = kg[kg["p_value"] < 0.2] # subset by p-value threshold
    
    for index, row in kg.iterrows():
    # for index, row in kg[:5].iterrows(): # uncomment for testing
    
        total_sampsize = int(row['num_patients_with_condition']+row['num_patients_without_condition']) # get total sample size
        total_sampsize = round(total_sampsize/10)*10 # round total sample size to nearest 10
        row["num_patients_with_condition"] + row["num_patients_without_condition"]

        id_dict = {} # this is the outter dict that holds inner dicts: subject_dict, association_dict, object_dict
        subject_dict = {} # inner dict
        association_dict = {} # inner dict
        object_dict = {} # inner dict
        source_dict = {} # inner dict (provides provenance as per TRAPI 1.4 standards )

        # id generated by concatenating the following: subject_id CURIE, object_id CURIE, AUCROC (removing decimal point) and p-value (removing decimal point)
        id_aucroc = str(row['auc_roc'])
        id_aucroc = id_aucroc.replace('.', '')
        id_pval = str(row['auc_roc'])
        id_pval = id_pval.replace('.', '')
        id_dict["_id"] = "{}_{}_{}_{}".format(row["subject"], row["object"], id_aucroc, id_pval)

        subject_dict["{}".format(row["subject"].split(':')[0])] = "{}".format(row["subject"].split(':')[1]) # create the subject dict from the rows of the df 
        subject_dict["id"] = row["subject"]
        subject_dict["name"] = row["subject_name"]
        subject_dict["type"] = row["subject_category"]

        association_dict["predicate"] = "{}".format(row["predicate"].split(':')[1]) # create the association dict from the rows of the df. Edge attributes need extra work. The predicate is separated out into qualified predicate by X-BTE annotation, so we don't have to worry about qualifiers here
        association_dict["edge_attributes"] = []
        
        source_dict["edge_sources"] = []
        
        association_dict["edge_attributes"].append(
            {
                "attribute_type_id":"biolink:has_supporting_study_result",
                "value":"We train a large collection of multivariable, binary logistic regression models on EHR data for each specific condition/disease/outcome. Features include labs, medications, and phenotypes. Directed edges point from risk factors to specific outcomes (diseases, phenotype, or medication exposure).",
                "attributes": [
                    {
                        "attribute_type_id": "biolink:supporting_study_method_type",
                        "value": "STATO:0000149",
                        "description": "Binomial logistic regression for analysis of dichotomous dependent variable (in this case, for having this particular condition/disease/outcome or not)"
                    },
                    {
                        "attribute_type_id":"biolink:update_date",
                        "value":row["provided_date"]
                    },
                    {
                        "attribute_type_id": "biolink:p_value",
                        "value": row["p_value"],
                        "description": "p-value for the feature's coefficient"
                    },
                    {
                        "attribute_type_id": "STATO:0000209",
                        "value": row["auc_roc"],
                        "description": "AUC-ROC of the logistic regression model"
                    },
                    {
                        "attribute_type_id": "STATO:0000565",
                        "value": row['feature_coefficient'],
                        "description": "log_odds_ratio"
                    },
                    {
                        "attribute_type_id": "biolink:supporting_study_cohort",
                        "value": "age < 18 excluded"
                    },
                    {
                        "attribute_type_id": "biolink:supporting_study_date_range",
                        "value": "2020-2022 (future prediction)"
                    },
                    {
                        "attribute_type_id": "biolink:supporting_study_size",
                        "value": "{}".format(int(total_sampsize)),
                        "description": "total_sample_size"
                    },
    #                 {
    #                     "attribute_type_id": "biolink:supporting_study_context",
    #                     "value": "Approximate # of patients with condition: {}".format(row["num_patients_with_condition"]) 
    #                 },
    #                 {
    #                     "attribute_type_id": "biolink:supporting_study_context",
    #                     "value": "Approximate # of patients without condition: {}".format(row["num_patients_without_condition"]) 
    #                 }
                ]
            }
        )
        association_dict["edge_attributes"].append(
            {
                "attribute_type_id":"biolink:primary_knowledge_source",
                "value":"infores:biothings-multiomics-ehr-risk",
                "value_type_id": "biolink:InformationResource",
                "value_url":  "http://smart-api.info/registry?q=d86a24f6027ffe778f84ba10a7a1861a",
                "description": "The EHR Risk KP is created and maintained by the Multiomics Provider team from the Institute for Systems Biology in Seattle, WA. Through a partnership with Providence/Swedish Health Services and Institute for Systems Biology, we analyze over 26 million EHRs. We use these records to train a large collection of interpretable machine learning models which are integrated into a single large Knowledge Graph, with directed edges pointing from risk factors to specific outcomes (diseases, phenotype, or medication exposure).",
            }
        )
        association_dict["edge_attributes"].append(
            {
                "attribute_type_id":"biolink:supporting_data_source",
                "value":"infores:providence-st-joseph-ehr",
                "value_type_id": "biolink:InformationResource",
                "value_url":  "https://github.com/NCATSTranslator/Translator-All/wiki/EHR-Risk-KP",
                "description": "A partnership with Providence/Swedish Health Services and Institute for Systems Biology allows analysis of 26 million EHRs from patients in seven states in the US, including Alaska, California, Montana, Oregon, Washington, Texas, and New Mexico. Please email data-access@isbscience.org for more information.",
            }
        )

        object_dict["{}".format(row["object"].split(':')[0])] = "{}".format(row["object"].split(':')[1]) # create the object dict from the rows of the df 
        object_dict["id"] = row["object"]
        object_dict["name"] = row["object_name"]
        object_dict["type"] = row["object_category"]
        
        source_dict["edge_sources"].append(
            {
                "resource_id": "infores:biothings-multiomics-ehr-risk",
                "resource_role": "primary_knowledge_source"
            }
        )
        
        source_dict["edge_sources"].append(
            {
                "resource_id": "infores:providence-st-joseph-ehr",
                "resource_role": "supporting_data_source"
            }
        )


        id_dict["subject"] = subject_dict # put the subject, association, and object dicts into the outer dict called id_dict
        id_dict["association"] = association_dict
        id_dict["object"] = object_dict
        id_dict["source"] = source_dict
        
        # print(json.dumps(id_dict, indent=2)) # uncomment for testing

        yield id_dict # comment for testing

def main():
	# data_folder = "../../data" # uncomment for testing
	parse_ehr_risk(data_folder) 

if __name__ == "__main__":
	main()

